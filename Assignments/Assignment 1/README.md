# Q1

***‚ÄúIf a machine is expected to be infallible, it cannot also be intelligent.‚Äù***

‚Äï Alan Turing


In October 1950,¬†Mind: A Quarterly Review of Psychology and Philosophy¬†published its 59th volume, featuring Alan Turing‚Äôs groundbreaking paper,¬†Computing Machinery and Intelligence. Turing‚Äôs provocative question‚ÄîCan machines think?‚Äîset the stage for a comprehensive exploration of the possibilities and challenges of machine intelligence. Rather than directly addressing the question, Turing took a pragmatic approach, focusing on the observable behaviour of machines and the philosophical, mathematical, and practical objections to the idea of machine intelligence. His work remains a cornerstone of artificial intelligence (AI) research, and his ideas continue to provoke debate. Reflecting on Turing‚Äôs predictions and the evolution of AI, it is worth examining which of his arguments still hold weight, whether his refutations remain valid, and how new objections have emerged in light of technological advancements.
Turing‚Äôs approach was unconventional yet rigorous. He did not shy away from objections that challenged his thesis; instead, he addressed them head-on, considering them worthy of serious discussion. One such objection, rooted in theology, argued that intelligence and consciousness are unique to humans because they possess a soul. This objection remains relevant today, as it touches on the moral and ethical considerations of granting AI systems any form of recognition or rights. Another significant objection came from Ada Lovelace, who asserted that¬†‚Äúa machine can never really do anything new.‚Äù¬†Lovelace argued that machines could only execute what they were explicitly programmed to do, lacking true creativity or understanding. While modern AI systems can generate seemingly novel content, they still rely on vast amounts of pre-existing data rather than independent reasoning. In this sense, Lovelace‚Äôs argument persists, as AI outputs can often be described as derivatives of their training data.
A further philosophical objection centres on the idea that intelligence requires subjective experience, or¬†qualia, which AI lacks. Even the most advanced AI systems today operate on pattern recognition and statistical inference rather than genuine understanding. From a mathematical perspective, G√∂del‚Äôs incompleteness theorem was cited as evidence that machines, bound by formal logical systems, could never achieve human-like intelligence. This theorem highlights that there are truths within formal systems that cannot be proven by the system itself, raising questions about the limits of machine reasoning.

Turing provided compelling counterarguments to these objections, some of which remain persuasive, while others continue to be debated. In response to Lovelace‚Äôs objection, Turing argued that machines could surprise their programmers, demonstrating behaviour that was not explicitly anticipated. While modern AI systems have indeed produced unexpected results‚Äîsuch as in-game playing or art generation‚Äîcritics still question whether this constitutes genuine creativity. To the argument from consciousness, Turing dismissed the need for subjective experience in defining intelligence, proposing that observable behaviour should be the criterion. This remains a contentious point, as many argue that true intelligence must involve self-awareness. Regarding the mathematical objection, Turing acknowledged the limitations imposed by formal systems but noted that humans also face logical constraints. However, AI systems today still struggle with tasks requiring deep reasoning beyond statistical inference.

Since Turing‚Äôs time, advancements in AI have introduced new objections and challenges. Ethical concerns, such as bias in AI systems, have become prominent. AI often reflects biases present in its training data, leading to issues of fairness and discrimination in areas like hiring and criminal justice. Additionally, the¬†explainability problem¬†has emerged as a significant challenge. Many modern AI systems, particularly deep learning models, function as ‚Äúblack boxes,‚Äù making their decision-making processes difficult to interpret and trust. Furthermore, while AI excels at specific tasks‚Äîsuch as image recognition or language processing‚Äîit lacks the broad adaptability and reasoning abilities of human intelligence. The question of whether machines can truly ‚Äúunderstand‚Äù or merely manipulate symbols without comprehension remains unresolved.
Turing predicted that by the year 2000, a machine would have a 30% chance of passing a five-minute Turing Test with an unskilled interrogator. While AI has made significant progress, the extent to which it has ‚Äúpassed‚Äù the Turing Test is debatable. Early attempts, such as the chatbot ELIZA in the 1960s, demonstrated that machines could simulate human-like conversation, but they lacked true understanding. In 2014, the chatbot Eugene Goostman reportedly fooled 33% of judges in a Turing Test, but critics argued that it relied on superficial tricks rather than genuine intelligence. Today, advanced models like ChatGPT can engage in sophisticated conversations, but they still struggle with nuanced reasoning and maintaining coherent long-term dialogues.

Turing‚Äôs paper remains foundational in the philosophy of AI. While some of his refutations remain strong, challenges such as consciousness, explainability, and bias persist. AI has made remarkable progress, but achieving true human-like intelligence remains an ongoing pursuit. Turing‚Äôs prediction about passing the Turing Test was ambitious, and while AI has come close, it has not fully realized his vision. Looking ahead, future AI research may need to redefine intelligence beyond the Turing Test, addressing deeper questions of understanding, adaptability, and ethical considerations. The evolution of AI continues to raise new ethical and philosophical questions, ensuring that Turing‚Äôs ideas will remain relevant for years to come.


# Q2

## **Playing a Decent Game of Table Tennis**  
**<span style="color:red;">üî¥ Not Feasible</span>**  

Historical context elucidates that the world began to see tennis-playing robots in the late 90s. An early model, **Ttmatc-101**, graced German catalogues in 1976. Since their debut more than half a century ago, these robots can put up a rigorous fight against most beginner-level players with little to no knowledge. However, even the most recent developments as late as just this previous year seem to decline significantly as the opponents‚Äô experience increases.  

A decent game between average players of an amateur level can lead to the ping-pong ball reaching speeds over **100 mph**, rendering matching the skill level of anyone above the beginner level of the game an obstacle yet to be tackled.  

In terms of the technical limitations, the aforementioned fast-paced nature of the sport demands **swift perception paired with impeccable motor control**, governed by rapid decision-making. Consequently, replicating these human abilities in robots is complex due to **limitations in sensor technology, processing speed, and mechanical dexterity**.  

---

## **Playing a Decent Game of Bridge at a Competitive Level**  
**<span style="color:red;">üü¢ Feasible</span>**  

According to *The Guardian* in an article published in March 2022, an AI agent known as **NooK** defeated **eight world champions** at bridge. Since bridge is a skill-based game, the AI was trained on different plays and was able to learn over time, much like human learning patterns.  

---

## **Writing an Intentionally Funny Story**  
**<span style="color:red;">üî¥ Not Feasible</span>**  

There have been attempts to create AI agents and models that can generate comedic elements, such as **Jon the Robot**. However, this particular branch, full of potential, is still in its infancy, primarily due to the **nature of comedy itself**.  

Comedy is heavily subjective; it is a product of **culture and various nuances** that are so hard to perfect that even accomplished comedians can face backlash. Conclusively, perhaps AI can always respond with a well-structured punchline if one demands it, but it's safe to say that **behind every punchline is an actual person** who has deemed it funny for the program running the AI itself.  

---

## **Giving Competent Legal Advice in a Specialized Area**  
**<span style="color:red;">üî¥ Not Feasible</span>**  

AI has yet to shine in fields that require **out-of-the-box thinking**. Legal advice in specialized cases is heavily incumbent on professional individuals who **not only know the law of their jurisdiction but are also well-versed in loopholes and reading between the lines** to benefit clients. This is something AI has little mastery over.  

---

## **Discovering Mathematical Theorems**  
**<span style="color:red;">üî¥ Not Feasible</span>**  

Ironically, even though AI is built upon mathematics, **math stems from abstract thinking** and analyzing the nature of phenomena to come to logical conclusions‚Äîsomething so far only the **human mind is capable of**.  

---

## **Performing a Surgical Operation**  
**<span style="color:red;">üü† Feasible and Not Feasible</span>**  

Human life is precious, and leaving it **completely** in the hands of a machine will always pose risks, regardless of the machine's efficacy rate. AI is already assisting surgeons in the **operating room**, but human supervision is something that will perhaps never be eradicated from the health sector.  

Quick **decision-making skills and adaptability** in unexpected situations remain **unique to the human brain**, making full automation infeasible for now.  

---

## **Unloading Any Dishwasher in Any Home**  
**<span style="color:red;">üî¥ Not Feasible</span>**  

AI-powered dishwashers for home use exist, but they do **not manually unload dishes**. This is due to:  

- The **sheer cost and risk** of installing hardware that does not yet exist at a **commercially viable level**.  
- Variability in **kitchen layouts and dish arrangements**, making it difficult to develop a generalize

#  Q3
## **Domain : Stock Trading**

An interesting domain where automated trading bots can be used to not only process and analyse statistical and financial data but also predict the trend a particular market will follow. Consequently, a more trained and reliable version would also execute the purchasing or selling of stock.
## Stock Trading Environment Characterization

| **Property**      | **Stock Trading Environment** | **Explanation** |
|------------------|----------------------------|----------------|
| **Accessible**  | ‚ùå No (Inaccessible)       | The agent does not have complete information (e.g., insider trading data, future events). |
| **Deterministic?** | ‚ùå No (Stochastic)         | Stock prices are affected by unpredictable factors like news, investor behavior, and economic events. |
| **Episodic?**    | ‚ùå No (Sequential)         | Each trade affects future decisions (e.g., holding or selling stocks later depends on previous trades). |
| **Static?**      | ‚ùå No (Dynamic)            | Stock prices, market trends, and external factors constantly change in real-time. |
| **Continuous?**  | ‚úÖ Yes (Continuous)       | Prices, trade volumes, and market trends change continuously rather than in fixed steps. |

### Summary
The **stock trading environment** is **inaccessible, stochastic, sequential, dynamic, and continuous**.  
A **learning-based agent** is best suited to handle this complex and unpredictable environment. This is so that the agent can familiarize itself with the dynamic nature of the market rather than rely on trends that almost always seem unreliable. 
However certain features for example the reaction to sudden changes would prove to be better governed by a **model-based reflex agent**.


# Q4
## **An agent that senses only partial information about the state cannot be perfectly rational**
False.

AI models depend on techniques such as fuzzy logic, probabilistic reasoning and many more powerful tools that enable them to navigate uncertainty. An interesting example is the Inventory management AI deployed at a leading US departmental store "WALMART"; their recent inventory model can accurately predict stock demand and reorder products considering certain trends' uncertainty.

## **There exist task environments in which no pure reflex agent can behave rationally**
True.

In the case of a more sophisticated environment, a reflex agent would prove moot. This is primarily because reflex agents only operate on an immediate percept reception scenario; they only take into account any current stimuli generated rather than a chain of events. For example, a game-playing agent that plays against an opponent in any skill-based game must keep track of previous plays to make an informed decision

## **There exists a task environment in which every agent is rational**
It is impossible to construct an environment where every agent is rational. Rationality is a property that depends on the agent's design, goals, and environment, and not all agents can meet these criteria simultaneously. For instance, an agent that is engaged in a game of tic tac toe; n tic-tac-toe, if both players are perfectly rational and play optimally, the game will always end in a draw. However, this is a very specific and idealized scenario. In reality, not all agents will be perfectly rational, and the presence of irrational agents is what makes the game dynamic and interesting.

 ## **The input to an agent program is the same as the input to the agent function**
 False.
 
 A function is structured logically to perceive the input. The function is an aspect of the overall program so while it may only provide one desired outcome, the program itself might be engaged in maintaining other features that complement the function and the overall output of the software/hardware. A Thermostat agent for example may have a function that turns the heat up and down according to the environment. On the other hand, the entirety of the program may simultaneously be engaged in timing the cooling system, managing the efficiency etc.

 ## **Every agent function is implementable by some program/machine combination**
False.

Some agent functions may require infinite memory or computational resources, making them impractical or impossible to implement. An agent that perfectly predicts stock market prices would need unlimited computational power, which is infeasible.

## **Suppose an agent selects its action uniformly at random from the set of possible actions. There exists a deterministic task environment in which this agent is rational**
True.

Imagine a scenario where an agent is tasked with selecting a number between 1 and 10, and the environment is designed such that no matter which number the agent chooses, the outcome is always the same (e.g., the agent always receives a fixed reward). In this case, since every action leads to an identical result, selecting a number uniformly at random is a rational strategy. There‚Äôs no advantage to choosing one number over another, so randomness doesn‚Äôt harm the agent‚Äôs performance, and it aligns perfectly with the environment‚Äôs deterministic nature. There are certain card games where the dealer always wins a share regardless of the outcome for other players a real-life situation partially similar to this one.

## **It is possible for a given agent to be perfectly rational in two distinct task environments.**
True.

If an agent chooses its action randomly from all possible options, there exists a deterministic task environment where this behaviour is rational. In such environments, the outcome is fixed regardless of the agent's choice, making random selection a perfectly reasonable strategy since no action provides an advantage over another
